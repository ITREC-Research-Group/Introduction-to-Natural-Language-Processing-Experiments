{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用LSTM进行语言建模\n",
    "\n",
    "<img src='img/rnn-lm.jpg' width=500>\n",
    "\n",
    "reference:\n",
    "- https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
    "- https://pytorch.org/tutorials/advanced/dynamic_quantization_tutorial.html?highlight=language%20modeling\n",
    "- https://github.com/pytorch/examples/tree/master/word_language_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 设置超参数\n",
    "\n",
    "一般，这些超参数是通过 argparse.ArgumentParser 从命令行中获取的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch_size=16, bptt=32, dropout=0.2, embedding_dim=200, hidden_dim=200, learning_rate=5, lm_data_dir='data/PennTreebank', max_grad_norm=1.0, model_save_path='data/save_model/lstm_lm.path', n_layers=4, num_train_epochs=20, seed=42, temperature=1.0, tie_weights=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "hparams = argparse.Namespace(**{\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 5,\n",
    "    'max_grad_norm': 1.,\n",
    "    'bptt': 32,  # sequence_length\n",
    "    'dropout': 0.2,\n",
    "    'embedding_dim': 200,\n",
    "    'hidden_dim': 200,\n",
    "    'n_layers': 4,\n",
    "    'tie_weights': True,\n",
    "    'seed': 42,\n",
    "    'num_train_epochs': 20,\n",
    "    'lm_data_dir': 'data/PennTreebank',\n",
    "    'model_save_path': 'data/save_model/lstm_lm.path',\n",
    "    'temperature': 1.\n",
    "})\n",
    "\n",
    "hparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载数据\n",
    "\n",
    "- 加载数据\n",
    "- tokenize\n",
    "- 建立词表，并将词映射为id\n",
    "- 将数据打包到batch中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Tokenization\n",
      "---------------------\n",
      "train: tokenizing ...\n",
      "val: tokenizing ...\n",
      "test: tokenizing ...\n",
      "Done!\n",
      "\n",
      "\n",
      "2. Build Vocab\n",
      "Done!\n",
      "\n",
      "\n",
      "3. To ids\n",
      "Done!\n",
      "\n",
      "\n",
      "4. batchify\n",
      "Done!\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9924"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PennTreebankCorpus import Corpus\n",
    "\n",
    "\n",
    "corpus = Corpus(root_dir=hparams.lm_data_dir)\n",
    "corpus.load_datasets()\n",
    "train_data, val_data, test_data = corpus.preprocess(hparams.batch_size)\n",
    "\n",
    "hparams.vocab_size = corpus.vocab_size()\n",
    "\n",
    "hparams.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60659, 16])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.size()\n",
    "# 加载词向量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.hparams = hparams    \n",
    "\n",
    "        self.drop = nn.Dropout(hparams.dropout)\n",
    "        self.embedding = nn.Embedding(hparams.vocab_size, hparams.embedding_dim)\n",
    "        self.rnn_layer = nn.LSTM(\n",
    "            hparams.embedding_dim,\n",
    "            hparams.hidden_dim, \n",
    "            hparams.n_layers,\n",
    "            dropout=hparams.dropout)\n",
    "\n",
    "        self.decoder = nn.Linear(hparams.hidden_dim, hparams.vocab_size)\n",
    "        if hparams.tie_weights:\n",
    "            assert hparams.embedding_dim == hparams.hidden_dim\n",
    "            self.decoder.weight = self.embedding.weight\n",
    "\n",
    "        # 参数初始化\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_range = 0.1\n",
    "        self.embedding.weight.data.uniform_(-init_range, init_range)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-init_range, init_range)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        # (L, B) => (L, B, embedding_dim)\n",
    "        emb = self.embedding(input)        \n",
    "        emb = self.drop(emb)\n",
    "\n",
    "        # emb (L, B, embedding_dim) => output (L, B, hidden_dim)\n",
    "        output, hidden = self.rnn_layer(emb, hidden)\n",
    "        output = self.drop(output)\n",
    "        \n",
    "        # (L, B, hidden_dim) => (L, B, vocab_size)\n",
    "        # 为每个位置预测下个词\n",
    "        decoded = self.decoder(output)\n",
    "        return decoded, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"\n",
    "        初始化 第一个隐状态和细胞状态\n",
    "        \"\"\"\n",
    "        weight = next(self.parameters())\n",
    "        return (weight.new_zeros(self.hparams.n_layers, batch_size, self.hparams.hidden_dim),\n",
    "                weight.new_zeros(self.hparams.n_layers, batch_size, self.hparams.hidden_dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (embedding): Embedding(9924, 200)\n",
       "  (rnn_layer): LSTM(200, 200, num_layers=4, dropout=0.2)\n",
       "  (decoder): Linear(in_features=200, out_features=9924, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(hparams)\n",
    "model.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=hparams.learning_rate, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i, hparams):\n",
    "    seq_len = min(hparams.bptt, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]\n",
    "    target = source[i+1:i+1+seq_len]\n",
    "    return data, target\n",
    "\n",
    "\n",
    "def repackage_hidden(h):\n",
    "    \"\"\"Wraps hidden states in new Tensors, to detach them from their history.\"\"\"\n",
    "\n",
    "    if isinstance(h, torch.Tensor):\n",
    "        return h.detach()\n",
    "    else:\n",
    "        return tuple(repackage_hidden(v) for v in h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import math\n",
    "\n",
    "def train(model, train_data, loss_func, optimizer, epoch_idx, hparams):\n",
    "    model.train()\n",
    "    hidden = model.init_hidden(hparams.batch_size)\n",
    "    \n",
    "    pbar = tqdm(range(0, train_data.size(0)-1, hparams.bptt))\n",
    "    pbar.set_description(f'Epoch {epoch_idx}')\n",
    "\n",
    "    \n",
    "    for i in pbar:\n",
    "        # left_context: (L, B)\n",
    "        # target: (L, B)\n",
    "        left_context, targets = get_batch(train_data, i, hparams)\n",
    "\n",
    "        left_context = left_context.cuda()\n",
    "        targets = targets.cuda()\n",
    "\n",
    "        output, hidden = model(left_context, hidden)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_func(output.view(-1, hparams.vocab_size), targets.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        # 梯度裁剪，防止梯度爆炸\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), hparams.max_grad_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "        # 混淆度：评估语言模型的一个指标\n",
    "        ppl = math.exp(loss.item())\n",
    "        pbar.set_postfix(loss=loss.item(), ppl=ppl)\n",
    "\n",
    "        # 中断梯度\n",
    "        hidden = repackage_hidden(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_val_data, loss_func, hparams):\n",
    "    model.eval()\n",
    "    hidden = model.init_hidden(hparams.batch_size)\n",
    "    total_loss = 0.\n",
    "\n",
    "    hidden = model.init_hidden(hparams.batch_size)\n",
    "    with torch.no_grad():\n",
    "        n_steps = 0\n",
    "        pbar = tqdm(range(0, test_val_data.size(0)-1, hparams.bptt))\n",
    "        pbar.set_description('Valid')\n",
    "        for i in pbar:\n",
    "            left_context, targets = get_batch(test_val_data, i, hparams)\n",
    "            \n",
    "            left_context = left_context.cuda()\n",
    "            targets = targets.cuda()\n",
    "\n",
    "            output, hidden = model(left_context, hidden)\n",
    "            hidden = repackage_hidden(hidden)\n",
    "            loss = loss_func(output.view(-1, hparams.vocab_size), targets.view(-1))\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            n_steps += 1\n",
    "    avg_loss = total_loss / n_steps\n",
    "    ppl = math.exp(avg_loss)\n",
    "    return avg_loss, ppl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 113.00it/s, loss=5.27, ppl=194]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 414.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 5.0441, PPL: 155, LR: 5                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 113.94it/s, loss=5.08, ppl=162]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 418.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.8678, PPL: 130, LR: 5                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 112.98it/s, loss=5.01, ppl=150]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 412.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.8040, PPL: 122, LR: 5                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|████████████████████████████████████████████████| 1896/1896 [00:17<00:00, 110.96it/s, loss=4.93, ppl=139]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 417.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.7751, PPL: 119, LR: 5                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 111.82it/s, loss=4.92, ppl=137]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 385.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.7862, PPL: 120, LR: 5                       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|████████████████████████████████████████████████| 1896/1896 [00:15<00:00, 120.39it/s, loss=4.76, ppl=117]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 414.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.5971, PPL: 99, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 113.28it/s, loss=4.63, ppl=103]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 413.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.5595, PPL: 96, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 116.56it/s, loss=4.63, ppl=102]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 414.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.5301, PPL: 93, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|███████████████████████████████████████████████| 1896/1896 [00:16<00:00, 114.33it/s, loss=4.53, ppl=93.1]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 383.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.5083, PPL: 91, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|███████████████████████████████████████████████| 1896/1896 [00:15<00:00, 123.51it/s, loss=4.5, ppl=89.8]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 419.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4906, PPL: 89, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 124.20it/s, loss=4.51, ppl=90.9]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 421.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4777, PPL: 88, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 125.53it/s, loss=4.44, ppl=84.5]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 418.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4633, PPL: 87, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 123.54it/s, loss=4.41, ppl=82.3]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 417.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4512, PPL: 86, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 122.66it/s, loss=4.41, ppl=82.3]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 411.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4379, PPL: 85, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|████████████████████████████████████████████████| 1896/1896 [00:16<00:00, 117.07it/s, loss=4.33, ppl=76]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 414.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4300, PPL: 84, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████████████████████████████████████████| 1896/1896 [00:16<00:00, 117.08it/s, loss=4.33, ppl=76.2]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 413.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4186, PPL: 83, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████████████████████████████████████████| 1896/1896 [00:16<00:00, 115.27it/s, loss=4.35, ppl=77.2]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 397.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4146, PPL: 83, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 123.42it/s, loss=4.32, ppl=75.3]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 418.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.4049, PPL: 82, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 124.28it/s, loss=4.39, ppl=80.5]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 421.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.3901, PPL: 81, LR: 1.25                       \n",
      "save model to data/save_model/lstm_lm.path\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████████████████████████████████████████| 1896/1896 [00:15<00:00, 118.71it/s, loss=4.27, ppl=71.5]\n",
      "Valid: 100%|████████████████████████████████████████████████████████████████████████| 151/151 [00:00<00:00, 421.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "[Validation] loss: 4.3925, PPL: 81, LR: 1.25                       \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_loss = None\n",
    "learning_rate = hparams.learning_rate\n",
    "\n",
    "for epoch_idx in range(hparams.num_train_epochs):\n",
    "    train(model, train_data, loss_func, optimizer, epoch_idx+1, hparams)\n",
    "    val_loss, ppl = evaluate(model, val_data, loss_func, hparams)\n",
    "    print(f'\\r[Validation] loss: {val_loss:.4f}, PPL: {ppl:.0f}, LR: {learning_rate}                       ')\n",
    "    \n",
    "    if not best_val_loss or val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), hparams.model_save_path)\n",
    "        print(F'save model to {hparams.model_save_path}\\n')\n",
    "        best_val_loss = val_loss\n",
    "    else:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            learning_rate /= 4\n",
    "            param_group['lr'] = learning_rate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTMModel(\n",
       "  (drop): Dropout(p=0.2, inplace=False)\n",
       "  (embedding): Embedding(9924, 200)\n",
       "  (rnn_layer): LSTM(200, 200, num_layers=4, dropout=0.2)\n",
       "  (decoder): Linear(in_features=200, out_features=9924, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTMModel(hparams)\n",
    "model.load_state_dict(torch.load(hparams.model_save_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[next_word] candidates: in and on of for to than with says \n",
      "in\n",
      "<sos> we have no useful information in\n",
      "[next_word] candidates: the a this recent which their our any n \n",
      "the\n",
      "<sos> we have no useful information in the\n",
      "[next_word] candidates: past world company u future market stock next country \n",
      ".\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(hparams.seed)\n",
    "torch.cuda.manual_seed(hparams.seed)\n",
    "\n",
    "\n",
    "input_sentence = ['<sos>', 'we', 'have', 'no', 'useful', 'information']\n",
    "\n",
    "input_ = torch.tensor([corpus.vocab[word] for word in input_sentence])\n",
    "input_ = input_.view(-1, 1)\n",
    "\n",
    "hidden = model.init_hidden(1)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(20):\n",
    "        # (4, 1, vocab_size)\n",
    "        output, hidden = model(input_, hidden)\n",
    "        # (1, vocab_size)\n",
    "        # 最后一个位置的预测结果\n",
    "        output = output[-1]\n",
    "        # (vocab_size)\n",
    "        word_weights = output.squeeze().div(hparams.temperature).exp()\n",
    "        # (10, )\n",
    "        topk_word = word_weights.topk(k=10)[1]\n",
    "        topk_word = [word_idx for word_idx in topk_word if word_idx not in (corpus.vocab['<eos>'], corpus.vocab['<unk>'])]\n",
    "\n",
    "        print('[next_word] candidates:', end=' ')\n",
    "        for word_idx in topk_word:\n",
    "            word = corpus.vocab.get_itos()[word_idx]\n",
    "#             word = corpus.vocab.itos[word_idx.item()]\n",
    "\n",
    "            print(f'{word}', end=' ')\n",
    "        print()\n",
    "\n",
    "        input_word = input()\n",
    "        if input_word == '.':\n",
    "            break\n",
    "        word_idx = corpus.vocab[input_word]\n",
    "        input_sentence.append(input_word)\n",
    "        print(' '.join(input_sentence))\n",
    "        # word_idx = topk_word[0]\n",
    "        input_= torch.tensor([word_idx]).view(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <eos> \n",
      "<sos> it has ruled that no magazine saying might draw new professional for any part to big insurance <eos> \n",
      "<sos> a white house spokesman called the rules of congress with appropriations safety and milk system by gte ' s market <eos> \n",
      "<sos> such losses are to likely said stop estimated the japanese sides <eos> \n",
      "<sos> the increasing start in recent months are n ' t expected to join the united aid program <eos> \n",
      "<sos> congress was n ' t likely to kill approved general government confidence in the wake of a federal bank <eos> \n",
      "<sos> the new jersey meeting "
     ]
    }
   ],
   "source": [
    "torch.manual_seed(hparams.seed)\n",
    "torch.cuda.manual_seed(hparams.seed)\n",
    "\n",
    "\n",
    "# input_ = torch.randint(hparams.vocab_size, (1, 1), dtype=torch.long)\n",
    "\n",
    "input_ = torch.tensor(corpus.vocab['<sos>'])\n",
    "input_ = input_.view(-1, 1)\n",
    "hidden = model.init_hidden(1)\n",
    "\n",
    "word = corpus.vocab.itos[input_.item()]\n",
    "print(word, end=' ')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(100):\n",
    "        output, hidden = model(input_, hidden)\n",
    "\n",
    "        word_weights = output.squeeze().div(1).exp()\n",
    "        word_weights[corpus.vocab['<unk>']] = 0.\n",
    "        word_idx = torch.multinomial(word_weights, 1)[0]\n",
    "\n",
    "        input_.fill_(word_idx)\n",
    "        word = corpus.vocab.itos[word_idx]\n",
    "        print(word, end=' ')\n",
    "        if word == '<eos>':\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 拓展\n",
    "\n",
    "1. LSTM得到的句子表示本身就可以用于下游任务\n",
    "1. LSTM的并行性不够友好，难以用于大规模语料上的训练 => Transformer\n",
    "2. 文本生成的解码策略：Greedy Search vs Beam Search\n",
    "\n",
    "refernece: https://huggingface.co/blog/how-to-generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38] *",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
